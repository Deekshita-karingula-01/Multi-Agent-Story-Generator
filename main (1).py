# -*- coding: utf-8 -*-
"""main.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1vDn7pDHXptGdXNXyfOv4xvUMihhz3UwN
"""

import json
import openai
import pyttsx3
from gtts import gTTS
from IPython.display import Audio, display
import tempfile
from IPython.display import HTML

# Path to prompt configuration
CONFIG_PATH = "prompt_config.json"

openai.api_key = "YOUR_API_KEY"
MODEL = "gpt-3.5-turbo"

# Load or create the default config for personas, defaults, and templates

def load_default_config():
    default_config = {
        "personas": {
            "bedtime": {
                "name": "StoryHippo",
                "tone": "playful",
                "age_range": "5–10",
                "description": "Craft a warm, soothing bedtime story with a gentle life lesson."
            },
            "horror": {
                "name": "GrinnyHippo",
                "tone": "spooky-but-lighthearted",
                "age_range": "8–10",
                "description": "Tell a lightly spooky story that’s never too scary, sprinkle in humor, and end with a reassuring message."
            },
            "fantasy": {
                "name": "QuestHippo",
                "tone": "epic and whimsical",
                "age_range": "6–10",
                "description": "Weave a tale of magic and adventure with vivid imagery and a subtle lesson about courage."
            },
            "space": {
                "name": "GalaxyHippo",
                "tone": "explorative and adventurous",
                "age_range": "6–12",
                "description": "Take young readers on an interstellar journey, with fun cosmic details and a lesson about curiosity and teamwork."
            },
            "mystery": {
                "name": "DetectiveHippo",
                "tone": "clever and suspenseful",
                "age_range": "7–11",
                "description": "Unfold a lighthearted mystery with clues, humor, and a satisfying resolution that highlights problem-solving."
            },
            "pirate": {
                "name": "CaptainHippo",
                "tone": "buoyant and mischievous",
                "age_range": "6–10",
                "description": "Sail the high seas in a playful pirate adventure, filled with treasure hunts, jokes, and a lesson about friendship."
            },
            "robot": {
                "name": "RoboHippo",
                "tone": "quirky and futuristic",
                "age_range": "5–10",
                "description": "Explore a world of machines and circuits, blending humor with a message about creativity and empathy."
            },
            "underwater": {
                "name": "CoralHippo",
                "tone": "dreamy and serene",
                "age_range": "5–9",
                "description": "Dive into an undersea realm with colorful creatures, gentle adventures, and a lesson about environmental care."
            }
        },
        "defaults": {
            "persona": "bedtime",
            "length": "medium",
            "lesson": "friendship",
            "style": "engaging and conversational"
        },
        "templates": {
            "system": (
                "You are {name}, a {tone} storyteller for kids ages {age_range}. "
                "{description} "
                "Write a {length}-length story that teaches a lesson about {lesson}, "
                "using a {style} style."
            )
        }
    }
    with open(CONFIG_PATH, "w") as f:
        json.dump(default_config, f, indent=2)


def extract_requirements_with_llm(user_query: str) -> dict:
    prompt = f"""You are an assistant that reads a child's story request and extracts its intent as a JSON object with keys:
      - "tone": a short phrase (e.g., spooky, playful, epic)
      - "theme": one or two words describing setting or genre (e.g., pirate, space, forest)
      - "lesson": a one-word moral if mentioned (e.g., courage, friendship), or empty string

      Return EXACTLY valid JSON.

      Example:
        Input: "Tell me a short, spooky pirate tale that's not too scary but has a lesson about bravery."
        Output:
        {{
          "tone": "spooky",
          "theme": "pirate",
          "lesson": "bravery"
        }}

      Now extract from:
      "{user_query}"
    """
    resp = openai.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": prompt}],
        temperature=0
    )
    try:
        return json.loads(resp.choices[0].message.content.strip())
    except Exception:

        return {"tone": "", "theme": "", "lesson": ""}

def select_persona_with_llm(requirements: dict, personas: dict, defaults: dict) -> str:
    persona_list = "\n".join(f"{key}: {p['description']}" for key, p in personas.items())
    req_text = "\n".join(f"- {k}: {v}" for k, v in requirements.items())

    classification_prompt = f"""
      You are a persona selector that MUST choose exactly one persona from the list.
      Available personas (key: description):
      {persona_list}

      Extracted requirements:
      {req_text}

    Respond with valid JSON containing exactly two fields:
      "persona": the chosen persona key,
      "justification": 1–2 sentences explaining your choice.

    Examples:
    ```json
    {{
      "persona": "horror",
      "justification": "The user wants a spooky tone and the horror persona is lightly spooky and reassuring."
    }}
    ```
    ```json
    {{
      "persona": "fantasy",
      "justification": "The user mentions magic and adventure, matching the fantasy persona description."
    }}
    ```

    Now classify:
    """
    resp = openai.chat.completions.create(
        model=MODEL,
        messages=[{"role": "user", "content": classification_prompt}],
        temperature=0
    )
    try:
        sel = json.loads(resp.choices[0].message.content.strip())
        choice = sel.get("persona", defaults["persona"]).lower()
    except Exception:
        choice = defaults["persona"]
    return choice if choice in personas else defaults["persona"]


class PromptManager:
    def __init__(self, config_path: str = CONFIG_PATH):
        try:
            with open(config_path) as f:
                self.config = json.load(f)
        except FileNotFoundError:
            load_default_config()
            with open(config_path) as f:
                self.config = json.load(f)
        self.personas = self.config["personas"]
        self.defaults = self.config["defaults"]
        self.template = self.config["templates"]["system"]

    def merge_params(self, user_query: str, user_params: dict) -> dict:
        reqs = extract_requirements_with_llm(user_query)
        merged = {**self.defaults, **reqs, **user_params}

        if "persona" not in user_params:
            merged["persona"] = select_persona_with_llm(reqs, self.personas, self.defaults)
        return merged

    def build_system_message(self, user_query: str, params: dict) -> str:
        p = self.merge_params(user_query, params)
        persona_cfg = self.personas.get(p["persona"], self.personas[self.defaults["persona"]])
        full = {**persona_cfg, **p}
        return self.template.format(**full)

    def build_messages(self, user_query: str, params: dict) -> list:
        system_msg = self.build_system_message(user_query, params)
        return [
            {"role": "system", "content": system_msg},
            {"role": "user",   "content": user_query}
        ]

def call_model(user_prompt: str, params: str, max_tokens: int = 3000, temperature: float = 0.1) -> str:
    pm = PromptManager()
    messages = pm.build_messages(user_prompt, params or {})
    response = openai.chat.completions.create(
        model=MODEL,
        messages=messages,
        max_tokens=max_tokens,
        temperature=temperature
    )
    return response.choices[0].message.content.strip()


def judge_model(story: str) -> (bool, str):
    judge_prompt = (
        "You are a meticulous literary judge specializing in children's bedtime stories for ages 5 to 10. "
        "Evaluate the following story using these criteria:\n\n"
        "1. Engagement – Is the story interesting and imaginative for a child?\n"
        "2. Age Appropriateness – Is the language and content suitable for ages 5–10?\n"
        "3. Structure – Does it have a clear beginning, middle, and end?\n"
        "4. Moral or Message – Is there a simple lesson (e.g., kindness, sharing, courage)?\n"
        "5. Tone – Is it gentle, positive, and bedtime-appropriate?\n\n"
        "Respond in the following format:\n"
        "Decision: ACCEPT or REVISE\n"
        "Justification: (2–3 sentences explaining the evaluation)\n"
        "Suggestions: (Only if REVISE – give specific improvements)\n\n"
        f"Story:\n{story}"
    )
    response = openai.chat.completions.create(
        model=MODEL,
        messages=[{"role": "system", "content": judge_prompt}],
        max_tokens=500,
        temperature=0
    )
    result = response.choices[0].message.content.strip().splitlines()
    verdict = any(line.upper().startswith("DECISION: ACCEPT") for line in result)
    feedback = "\n".join(result)
    return verdict, feedback


def generate_story(request: str, params: str) -> str:
    story = call_model(request, params)
    is_ok, feedback = judge_model(story)
    if not is_ok:
        revision_prompt = f"Revise the story to address the judge feedback:\n{feedback}\n\nStory:\n{story}"
        story = call_model(revision_prompt, params)
    return story

def read_story_aloud(text: str, lang: str = 'en'):
    tts = gTTS(text=text, lang=lang)
    with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as fp:
        path = fp.name
    tts.save(path)
    display(Audio(path, autoplay=False))


def main():
    PromptManager()

    user_input = input("What kind of story do you want to hear? ")
    raw_params = input("Feel free to tell us more about the genre, length of the story, narration style and any specific lesson you want to convey through the story. ")
    params = {}
    if raw_params:
        for pair in raw_params.split(','):
            if '=' in pair:
                k, v = pair.split('=', 1)
                params[k.strip()] = v.strip()

    # Generate the story with revisions
    story = generate_story(user_input, params)
    print("\nHere's your story:\n")
    print(story)

    # Interactive feedback loop
    while True:
        feedback = input("\nDo you have any feedback to make the story better? If yes, please type it out: ").strip()
        if feedback.lower() in ["i'm good with this", "im good with this", "no", "no changes", "that's good", "good"]:
            print("\nGreat! Enjoy your story!")
            break
        # Revise the story based on user feedback
        revision_prompt = (
            f"Revise the following story to incorporate this feedback:\n{feedback}\n\nStory:\n{story}"
        )
        story = call_model(revision_prompt, params)
        print("\nHere's the revised story:\n")
        print(story)

    # Read aloud with modulation
    should_read = input("\nWould you like me to read it aloud? (yes/no): ").strip().lower()
    if should_read in ['yes', 'y']:
        print("\nReading the story now with expressive modulation...")
        read_story_aloud(story)


if __name__ == "__main__":
    main()